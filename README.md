<!-- Logo de LATAM -->
<p align="center">
  <img src="https://pressreleasecom.wordpress.com/wp-content/uploads/2017/06/pressrelease-logo-latam-airlines.jpg" width="300">
</p>

<!-- T칤tulo del Proyecto -->
<h1 align="center" style="color: #A01F30;">Documentaci칩n del Proyecto de An치lisis de Tweets</h1>

<!-- Descripci칩n General -->
<p align="center" style="color: #003366; font-size: 18px;">
  Bienvenido a la documentaci칩n del proyecto de an치lisis de tweets. Este proyecto utiliza PySpark para procesar y analizar un archivo JSON de tweets almacenado en Azure Data Lake Storage (ADLS).
</p>

<!-- Detalles del Proyecto -->
## Descripci칩n del Proyecto

Este proyecto se enfoca en el an치lisis de datos de tweets para obtener insights valiosos. Los principales objetivos del proyecto son:

1. 游늰 Identificar las 10 fechas con la mayor cantidad de tweets y el usuario m치s activo en cada una de esas fechas.
2. 游땕 Encontrar los 10 emojis m치s usados y su respectivo conteo.
3. 游끥 Determinar los 10 usuarios m치s influyentes en funci칩n del conteo de menciones (@).

## Pasos del Proceso

### 1. Inicializaci칩n y Configuraci칩n
- Definir las rutas base para los archivos de datos, de salida y de logs.
- Crear los directorios de salida y logs si no existen.
- Configurar un logger personalizado para registrar mensajes en un archivo de texto.

### 2. Ejecuci칩n del An치lisis
Cada uno de los an치lisis se realiza a trav칠s de funciones espec칤ficas, optimizadas para el uso eficiente del tiempo y la memoria.

- **[游늰 An치lisis de Fechas y Usuarios Activos](docs/q1_memory.md)**
- **[游땕 An치lisis de Emojis Usados](docs/q2_memory.md)**
- **[游끥 An치lisis de Usuarios Influyentes](docs/q3_memory.md)**

### 3. Resultados y Logs
- Los resultados se guardan en formato Delta en ADLS.
- Los detalles de la ejecuci칩n se registran en un archivo de log para referencia futura.

### Cosas que se asumen

1. **Ingesta de Datos**:
   - La data fue previamente ingestada desde Google Drive hacia Azure Data Lake. Esto se debe a que el antivirus de Google Drive impide usar un conector o importar mediante un trigger la data. En cualquier otro caso, se podr칤a conectar a una fuente externa como una base de datos o mediante alg칰n API.

2. **Procesamiento por Lotes (Batch)**:
   - El procesamiento se realiza en lotes (batch) y la data se consulta en la ruta del datalake:
     ```markdown
     https://rawlatamdata.blob.core.windows.net/rawdata/tweets.json.zip
     ```
     Luego, se descomprime en formato JSON en:
     ```markdown
     https://rawlatamdata.blob.core.windows.net/processeddata/farmers-protest-tweets-2021-2-4.json
     ```

3. **Ejecuci칩n Manual del Pipeline**:
   - El pipeline de ingesta se ejecuta manualmente, leyendo el archivo almacenado en el Data Lake. Asumiendo que esta parte fuese automatizada, se podr칤a establecer un trigger peri칩dico para traer la data desde una fuente externa con cada ejecuci칩n. Sin embargo, el ejercicio actual no lo requiere.

4. **Cluster Interactivo para Procesamiento**:
   - Para el procesamiento de la informaci칩n y los c치lculos, se utiliz칩 Databricks con un cl칰ster interactivo. Este cl칰ster puede ser reemplazado por un job cluster o un pool de instancias para reducir costos. No obstante, para este ejercicio, se utiliza un cl칰ster interactivo por facilidad de uso y demostraci칩n.

   **Configuraci칩n del Cl칰ster**:
   - **Cluster ID**: `0619-233222-rjlnjfll`
   - **Usuario Creador**: `juan.afanador24@hotmail.com`
   - **Tipo de Nodo**: `Standard_DS3_v2`
   - **Versi칩n de Spark**: `15.2.x-scala2.12`
   - **M치ximo de N칰cleos**: `4`
   - **Memoria Total**: `14.3 GB`
   - **Tiempo de Autoterminado**: `30 minutos`
   - **Tipo de Disponibilidad**: `ON_DEMAND_AZURE`

5. **Seguridad y Almacenamiento de Credenciales**:
   - Para proteger credenciales y mantener la consistencia de las rutas, se opt칩 por almacenar datos sensibles en Azure Key Vault junto con Unity Catalog.

# Gu칤a Paso a Paso del Proceso de Orquestaci칩n

## Pipeline de Orquestaci칩n en Azure Data Factory

### Descripci칩n General

Este proceso de orquestaci칩n est치 dise침ado para gestionar la ingesta, el procesamiento y la transformaci칩n de datos de tweets almacenados en Azure Data Lake Storage (ADLS). La orquestaci칩n se divide en dos pipelines principales: `Raw_ingestion` para la ingesta de datos en bruto y `Refined_ingestion` para el procesamiento y an치lisis de datos refinados.

### Pasos del Proceso

1. **Pipeline de Orquestaci칩n Principal**

    El pipeline principal, llamado `Orchestration`, orquesta la ejecuci칩n de dos pipelines subordinados:
    
    - **Bronze**: Ejecuta el pipeline `Raw_ingestion`.
    - **Silver**: Ejecuta el pipeline `Refined_ingestion` despu칠s de la finalizaci칩n exitosa del pipeline `Raw_ingestion`.

2. **Pipeline de Ingesta Bruta (Raw_ingestion)**

    Este pipeline se encarga de leer los datos en formato ZIP desde Azure Data Lake, descomprimirlos y almacenarlos en formato JSON en una ubicaci칩n espec칤fica en el Data Lake.
    
    - **Actividad de Ingesta de Datos**: Se configura una actividad de copia que lee los archivos ZIP desde el Data Lake, los descomprime y los almacena en formato JSON. La configuraci칩n incluye detalles sobre la fuente (Azure Blob Storage), el destino (Azure Blob Storage) y las configuraciones de formato de archivo.

3. **Pipeline de Ingesta Refinada (Refined_ingestion)**

    Este pipeline se encarga de ejecutar una serie de notebooks de Databricks que realizan diferentes c치lculos y transformaciones en los datos. Cada notebook est치 dise침ado para un prop칩sito espec칤fico de procesamiento y an치lisis.

    #### Actividades en `Refined_ingestion`:

    - **q1_memory**: 
        - Calcula las 10 fechas con la mayor cantidad de tweets.
        - Identifica el usuario con m치s tweets en cada una de esas fechas.
        - Optimiza el uso de memoria durante el procesamiento.
    
    - **q1_time**:
        - Calcula las 10 fechas con la mayor cantidad de tweets.
        - Identifica el usuario con m치s tweets en cada una de esas fechas.
        - Optimiza el tiempo de ejecuci칩n del proceso.
    
    - **q2_memory**:
        - Calcula los 10 emojis m치s usados y su conteo.
        - Optimiza el uso de memoria durante el procesamiento.
    
    - **q2_time**:
        - Calcula los 10 emojis m치s usados y su conteo.
        - Optimiza el tiempo de ejecuci칩n del proceso.
    
    - **q3_memory**:
        - Calcula los 10 usuarios m치s influyentes en funci칩n del conteo de menciones.
        - Optimiza el uso de memoria durante el procesamiento.
    
    - **q3_time**:
        - Calcula los 10 usuarios m치s influyentes en funci칩n del conteo de menciones.
        - Optimiza el tiempo de ejecuci칩n del proceso.

    Cada una de estas actividades est치 configurada para ejecutarse de manera secuencial o en paralelo, dependiendo de las dependencias definidas. Cada notebook recibe como par치metro la ruta del archivo JSON en el Data Lake y ejecuta sus respectivas tareas de procesamiento.



## Posibles Optimizaciones Futuras

- **Optimizaci칩n de Particiones**: Ajustar el n칰mero de particiones basadas en el tama침o del dataset para mejorar el paralelismo y el rendimiento.
- **Uso de `broadcast` para DataFrames Peque침os**: Utilizar la funci칩n `broadcast` de Spark para DataFrames peque침os que se unen frecuentemente, para optimizar el tiempo de uni칩n.
- **Manejo Avanzado de Errores**: Implementar estrategias de reintento y manejo de errores m치s detalladas para mejorar la robustez del proceso.
- **Escalado Autom치tico**: Configurar el escalado autom치tico del cl칰ster de Databricks para manejar din치micamente cargas de trabajo variables y optimizar el costo.
- **Profiling de C칩digo**: Realizar un profiling detallado del c칩digo utilizando herramientas como `PySpark Profiler` para identificar y optimizar partes espec칤ficas del c칩digo que consumen m치s recursos.

---

<p align="center" style="color: #A01F30;">
  Proyecto realizado por Juan Jos칠 Afanador
</p>
